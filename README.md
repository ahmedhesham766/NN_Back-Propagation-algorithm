Data Preprocessing: Handled missing values and normalized the dataset for better performance. The dataset was split into training and testing sets to evaluate the model.

Neural Network Architecture: Designed a customizable deep learning model with support for different activation functions (sigmoid and tanh), multiple layers, and adjustable learning rates.

Back-Propagation Implementation: Implemented the back-propagation algorithm to update the weights and biases of the neural network based on the error rate obtained in the output layer.

Model Training: Trained the neural network on the training dataset and optimized the parameters through iterative updates.

Model Evaluation: Evaluated the model's performance using metrics like accuracy and confusion matrices. Visualized the results to analyze the model's effectiveness.
